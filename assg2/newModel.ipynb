{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seeing-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Scores: [75.0, 83.33333333333334, 75.0, 75.0, 75.0, 75.0, 91.66666666666666, 66.66666666666666, 91.66666666666666, 58.333333333333336]\n",
      "Mean Accuracy: 76.667%\n",
      "[0, 0, 0, 0, 0.6666666666666666, 0, 0, 0, 0, 0]\n",
      "0.06666666666666667\n",
      "2\n",
      "Scores: [82.35294117647058, 64.70588235294117, 47.05882352941176, 52.94117647058824, 76.47058823529412, 70.58823529411765, 70.58823529411765, 64.70588235294117, 52.94117647058824, 88.23529411764706]\n",
      "Mean Accuracy: 67.059%\n",
      "[0.25, 0, 0.6666666666666666, 0, 0.3333333333333333, 0, 0.5714285714285715, 0.3333333333333333, 0.4, 0]\n",
      "0.2554761904761905\n",
      "3\n",
      "Scores: [75.86206896551724, 96.55172413793103, 89.65517241379311, 93.10344827586206, 82.75862068965517, 79.3103448275862, 93.10344827586206, 93.10344827586206, 89.65517241379311, 93.10344827586206]\n",
      "Mean Accuracy: 88.621%\n",
      "[0.5, 0, 0.28571428571428575, 0, 0.6, 0, 0.25, 0.3333333333333333, 0, 0]\n",
      "0.1969047619047619\n",
      "4\n",
      "Scores: [74.28571428571429, 74.28571428571429, 77.14285714285715, 60.0, 68.57142857142857, 71.42857142857143, 57.14285714285714, 65.71428571428571, 65.71428571428571, 60.0]\n",
      "Mean Accuracy: 67.429%\n",
      "[0.5714285714285715, 0.15384615384615383, 0.3333333333333333, 0.3333333333333333, 0.25, 0.3333333333333333, 0.1818181818181818, 0, 0.25, 0]\n",
      "0.2407092907092907\n",
      "5\n",
      "Scores: [71.62162162162163, 68.91891891891892, 77.02702702702703, 67.56756756756756, 71.62162162162163, 74.32432432432432, 70.27027027027027, 75.67567567567568, 81.08108108108108, 81.08108108108108]\n",
      "Mean Accuracy: 73.919%\n",
      "[0.375, 0.3, 0.09523809523809525, 0.5333333333333333, 0.2727272727272727, 0.14285714285714285, 0.08695652173913043, 0.19999999999999998, 0.15384615384615383, 0.16666666666666669]\n",
      "0.2326625186407795\n",
      "6\n",
      "Scores: [78.26086956521739, 78.26086956521739, 86.95652173913044, 78.26086956521739, 91.30434782608695, 86.95652173913044, 95.65217391304348, 78.26086956521739, 69.56521739130434, 95.65217391304348]\n",
      "Mean Accuracy: 83.913%\n",
      "[0.5714285714285714, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0]\n",
      "0.09047619047619046\n",
      "7\n",
      "Scores: [50.0, 25.0, 50.0, 50.0, 50.0, 75.0, 50.0, 50.0, 100.0, 50.0]\n",
      "Mean Accuracy: 55.000%\n",
      "[0, 0, 0.4, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.04\n",
      "8\n",
      "Scores: [87.87878787878788, 93.93939393939394, 84.84848484848484, 93.93939393939394, 96.96969696969697, 81.81818181818183, 96.96969696969697, 96.96969696969697, 96.96969696969697, 93.93939393939394]\n",
      "Mean Accuracy: 92.424%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "9\n",
      "Scores: [55.00000000000001, 55.00000000000001, 51.66666666666667, 55.00000000000001, 60.0, 63.33333333333333, 60.0, 56.666666666666664, 51.66666666666667, 58.333333333333336]\n",
      "Mean Accuracy: 56.667%\n",
      "[0.11764705882352941, 0, 0.26666666666666666, 0.14814814814814814, 0.2, 0.08695652173913043, 0.28571428571428564, 0.13333333333333336, 0.14285714285714288, 0.18181818181818182]\n",
      "0.1563141339100418\n",
      "10\n",
      "Scores: [74.71264367816092, 81.60919540229885, 85.0574712643678, 74.71264367816092, 83.9080459770115, 80.45977011494253, 83.9080459770115, 81.60919540229885, 88.50574712643679, 82.75862068965517]\n",
      "Mean Accuracy: 81.724%\n",
      "[0.2857142857142857, 0, 0.13333333333333333, 0.14285714285714288, 0.2857142857142857, 0.28571428571428575, 0.30769230769230765, 0.1818181818181818, 0.33333333333333337, 0.28571428571428575]\n",
      "0.2241891441891442\n",
      "11\n",
      "Scores: [72.91666666666666, 76.04166666666666, 86.45833333333334, 77.08333333333334, 80.20833333333334, 76.04166666666666, 79.16666666666666, 71.875, 69.79166666666666, 72.91666666666666]\n",
      "Mean Accuracy: 76.250%\n",
      "[0.375, 0, 0.2, 0.1818181818181818, 0.11111111111111112, 0, 0.11764705882352942, 0.3529411764705882, 0.34782608695652173, 0.33333333333333326]\n",
      "0.20196769485132657\n",
      "12\n",
      "Scores: [100.0, 83.33333333333334, 100.0, 83.33333333333334, 100.0, 83.33333333333334, 83.33333333333334, 100.0, 66.66666666666666, 100.0]\n",
      "Mean Accuracy: 90.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "13\n",
      "Scores: [100.0, 100.0, 100.0, 100.0, 50.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Mean Accuracy: 95.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "14\n",
      "Scores: [27.27272727272727, 45.45454545454545, 36.36363636363637, 45.45454545454545, 36.36363636363637, 36.36363636363637, 27.27272727272727, 54.54545454545454, 36.36363636363637, 45.45454545454545]\n",
      "Mean Accuracy: 39.091%\n",
      "[0.28571428571428575, 0, 0, 0, 0.22222222222222224, 0.4, 0.4, 0, 0, 0.5]\n",
      "0.1807936507936508\n",
      "15\n",
      "Scores: [83.33333333333334, 91.66666666666666, 91.66666666666666, 83.33333333333334, 95.83333333333334, 87.5, 87.5, 87.5, 87.5, 83.33333333333334]\n",
      "Mean Accuracy: 87.917%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "16\n",
      "Scores: [85.71428571428571, 80.0, 82.85714285714286, 85.71428571428571, 82.85714285714286, 74.28571428571429, 82.85714285714286, 82.85714285714286, 94.28571428571428, 80.0]\n",
      "Mean Accuracy: 83.143%\n",
      "[0, 0, 0, 0, 0, 0.28571428571428575, 0, 0, 0, 0]\n",
      "0.028571428571428574\n",
      "17\n",
      "Scores: [44.44444444444444, 62.96296296296296, 62.96296296296296, 81.48148148148148, 62.96296296296296, 62.96296296296296, 62.96296296296296, 66.66666666666666, 51.85185185185185, 51.85185185185185]\n",
      "Mean Accuracy: 61.111%\n",
      "[0, 0.28571428571428575, 0, 0.5, 0.5, 0, 0, 0.4, 0, 0]\n",
      "0.1685714285714286\n",
      "18\n",
      "Scores: [80.0, 70.0, 63.33333333333333, 73.33333333333333, 50.0, 83.33333333333334, 63.33333333333333, 60.0, 86.66666666666667, 73.33333333333333]\n",
      "Mean Accuracy: 70.333%\n",
      "[0, 0, 0.5, 0.4444444444444444, 0, 0, 0, 0, 0.25, 0.4]\n",
      "0.15944444444444444\n",
      "19\n",
      "Scores: [58.06451612903226, 74.19354838709677, 67.74193548387096, 67.74193548387096, 67.74193548387096, 80.64516129032258, 70.96774193548387, 64.51612903225806, 70.96774193548387, 61.29032258064516]\n",
      "Mean Accuracy: 68.387%\n",
      "[0.25, 0, 0.25, 0.5, 0, 0, 0, 0.28571428571428575, 0, 0.22222222222222224]\n",
      "0.1507936507936508\n",
      "20\n",
      "Scores: [91.66666666666666, 83.33333333333334, 83.33333333333334, 75.0, 83.33333333333334, 86.11111111111111, 75.0, 77.77777777777779, 83.33333333333334, 77.77777777777779]\n",
      "Mean Accuracy: 81.667%\n",
      "[0.3333333333333333, 0, 0.4444444444444445, 0, 0, 0.2222222222222222, 0, 0, 0.28571428571428575, 0.2]\n",
      "0.14857142857142858\n",
      "21\n",
      "Scores: [100.0, 91.83673469387756, 100.0, 95.91836734693877, 95.91836734693877, 100.0, 93.87755102040816, 100.0, 95.91836734693877, 95.91836734693877]\n",
      "Mean Accuracy: 96.939%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "22\n",
      "Scores: [0.0, 100.0, 100.0, 50.0, 100.0, 0.0, 100.0, 100.0, 50.0, 100.0]\n",
      "Mean Accuracy: 70.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "23\n",
      "Scores: [92.3076923076923, 61.53846153846154, 69.23076923076923, 76.92307692307693, 53.84615384615385, 69.23076923076923, 69.23076923076923, 46.15384615384615, 69.23076923076923, 69.23076923076923]\n",
      "Mean Accuracy: 67.692%\n",
      "[0, 0, 0, 0, 0, 0, 0.6666666666666666, 0, 0, 0.888888888888889]\n",
      "0.15555555555555556\n",
      "24\n",
      "Scores: [70.0, 50.0, 60.0, 40.0, 40.0, 80.0, 90.0, 90.0, 60.0, 70.0]\n",
      "Mean Accuracy: 65.000%\n",
      "[0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.05\n",
      "25\n",
      "Scores: [35.0, 45.0, 45.0, 40.0, 30.0, 30.0, 35.0, 40.0, 30.0, 50.0]\n",
      "Mean Accuracy: 38.000%\n",
      "[0, 0, 1.0, 0, 0, 0.5, 0, 1.0, 0, 0]\n",
      "0.25\n",
      "26\n",
      "Scores: [42.10526315789473, 57.89473684210527, 42.10526315789473, 52.63157894736842, 52.63157894736842, 47.368421052631575, 36.84210526315789, 36.84210526315789, 52.63157894736842, 47.368421052631575]\n",
      "Mean Accuracy: 46.842%\n",
      "[0, 0.2, 0.18181818181818182, 0.22222222222222224, 0.5454545454545454, 0, 0, 0.25, 0, 0]\n",
      "0.13994949494949496\n",
      "27\n",
      "Scores: [54.166666666666664, 45.83333333333333, 54.166666666666664, 37.5, 29.166666666666668, 37.5, 25.0, 54.166666666666664, 25.0, 45.83333333333333]\n",
      "Mean Accuracy: 40.833%\n",
      "[0.3333333333333333, 0.13333333333333333, 0.5, 0.125, 0.4, 0.25, 0.2222222222222222, 0.26666666666666666, 0, 0.3076923076923077]\n",
      "0.25382478632478633\n",
      "28\n",
      "Scores: [32.35294117647059, 55.88235294117647, 29.411764705882355, 29.411764705882355, 32.35294117647059, 44.11764705882353, 47.05882352941176, 44.11764705882353, 52.94117647058824, 47.05882352941176]\n",
      "Mean Accuracy: 41.471%\n",
      "[0.20000000000000004, 0.23529411764705882, 0, 0.5454545454545454, 0.5555555555555556, 0.5384615384615384, 0.4444444444444445, 0.15384615384615383, 0.4, 0.26666666666666666]\n",
      "0.3339723022075963\n",
      "29\n",
      "Scores: [0.0, 50.0, 50.0, 100.0, 50.0, 0.0, 50.0, 50.0, 50.0, 100.0]\n",
      "Mean Accuracy: 50.000%\n",
      "[0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0]\n",
      "0.2\n",
      "30\n",
      "Scores: [66.66666666666666, 66.66666666666666, 66.66666666666666, 33.33333333333333, 100.0, 66.66666666666666, 66.66666666666666, 33.33333333333333, 66.66666666666666, 0.0]\n",
      "Mean Accuracy: 56.667%\n",
      "[0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0, 0.5, 0, 0.6666666666666666, 0, 0]\n",
      "0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "Scores: [100.0, 50.0, 25.0, 50.0, 50.0, 25.0, 100.0, 75.0, 75.0, 25.0]\n",
      "Mean Accuracy: 57.500%\n",
      "[0, 0, 0, 1.0, 0, 0.6666666666666666, 0.6666666666666666, 0, 0, 0]\n",
      "0.2333333333333333\n",
      "32\n",
      "Scores: [50.0, 100.0, 50.0, 100.0, 100.0, 50.0, 100.0, 100.0, 100.0, 50.0]\n",
      "Mean Accuracy: 80.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "33\n",
      "Scores: [100.0, 100.0, 0.0, 100.0, 50.0, 50.0, 100.0, 100.0, 50.0, 50.0]\n",
      "Mean Accuracy: 70.000%\n",
      "[0, 0, 0.6666666666666666, 0, 0, 0, 0.6666666666666666, 0.6666666666666666, 0, 0.6666666666666666]\n",
      "0.26666666666666666\n",
      "34\n",
      "Scores: [0.0, 50.0, 50.0, 50.0, 0.0, 50.0, 50.0, 50.0, 50.0, 0.0]\n",
      "Mean Accuracy: 35.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "35\n",
      "Scores: [75.0, 100.0, 75.0, 75.0, 75.0, 75.0, 25.0, 75.0, 75.0, 100.0]\n",
      "Mean Accuracy: 75.000%\n",
      "[0.5, 0, 0, 0, 0, 0, 1.0, 0, 0, 0.6666666666666666]\n",
      "0.21666666666666665\n",
      "36\n",
      "Scores: [90.9090909090909, 92.42424242424242, 77.27272727272727, 78.78787878787878, 86.36363636363636, 89.39393939393939, 92.42424242424242, 89.39393939393939, 83.33333333333334, 83.33333333333334]\n",
      "Mean Accuracy: 86.364%\n",
      "[0.28571428571428575, 0, 0, 0.3529411764705882, 0.125, 0.4, 0, 0.1818181818181818, 0.2, 0.16666666666666666]\n",
      "0.17121403106697225\n",
      "37\n",
      "Scores: [94.11764705882352, 88.23529411764706, 100.0, 94.11764705882352, 94.11764705882352, 100.0, 82.35294117647058, 64.70588235294117, 70.58823529411765, 82.35294117647058]\n",
      "Mean Accuracy: 87.059%\n",
      "[0.6666666666666666, 1.0, 0.5, 0.4, 0, 0.5, 0.6666666666666666, 0.5, 0.8, 0.6666666666666666]\n",
      "0.57\n",
      "38\n",
      "Scores: [100.0, 75.0, 75.0, 75.0, 50.0, 50.0, 100.0, 100.0, 75.0, 75.0]\n",
      "Mean Accuracy: 77.500%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "39\n",
      "Scores: [75.0, 75.0, 100.0, 50.0, 75.0, 75.0, 50.0, 75.0, 50.0, 75.0]\n",
      "Mean Accuracy: 70.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "40\n",
      "Scores: [100.0, 50.0, 100.0, 50.0, 100.0, 0.0, 50.0, 100.0, 50.0, 100.0]\n",
      "Mean Accuracy: 70.000%\n",
      "[1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0, 1.0, 1.0, 0, 0]\n",
      "0.6\n",
      "41\n",
      "Scores: [93.33333333333333, 73.33333333333333, 73.33333333333333, 86.66666666666667, 100.0, 86.66666666666667, 86.66666666666667, 100.0, 66.66666666666666, 86.66666666666667]\n",
      "Mean Accuracy: 85.333%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "42\n",
      "Scores: [59.09090909090909, 59.09090909090909, 81.81818181818183, 68.18181818181817, 63.63636363636363, 63.63636363636363, 63.63636363636363, 68.18181818181817, 54.54545454545454, 90.9090909090909]\n",
      "Mean Accuracy: 67.273%\n",
      "[0.3333333333333333, 0.25, 0.5714285714285715, 0, 0.2222222222222222, 0.28571428571428575, 0.4615384615384615, 0.4, 0.28571428571428575, 0.33333333333333337]\n",
      "0.31432844932844933\n",
      "43\n",
      "Scores: [80.0, 56.00000000000001, 56.00000000000001, 80.0, 60.0, 60.0, 64.0, 40.0, 80.0, 56.00000000000001]\n",
      "Mean Accuracy: 63.200%\n",
      "[0.18181818181818182, 0.3333333333333333, 0.5, 0.3076923076923077, 0.28571428571428575, 0.25, 0, 0.37499999999999994, 0, 0.25]\n",
      "0.24835581085581088\n",
      "44\n",
      "Scores: [83.33333333333334, 66.66666666666666, 100.0, 83.33333333333334, 83.33333333333334, 100.0, 83.33333333333334, 100.0, 66.66666666666666, 83.33333333333334]\n",
      "Mean Accuracy: 85.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "45\n",
      "Scores: [100.0, 50.0, 0.0, 0.0, 50.0, 50.0, 100.0, 100.0, 100.0, 50.0]\n",
      "Mean Accuracy: 60.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "46\n",
      "Scores: [25.0, 100.0, 75.0, 75.0, 75.0, 75.0, 25.0, 25.0, 50.0, 100.0]\n",
      "Mean Accuracy: 62.500%\n",
      "[1.0, 0.6666666666666666, 0.6666666666666666, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.2333333333333333\n",
      "47\n",
      "Scores: [94.11764705882352, 87.05882352941177, 78.82352941176471, 88.23529411764706, 82.35294117647058, 89.41176470588236, 82.35294117647058, 88.23529411764706, 89.41176470588236, 88.23529411764706]\n",
      "Mean Accuracy: 86.824%\n",
      "[0.2222222222222222, 0.25, 0.36363636363636365, 0.25, 0, 0, 0.14285714285714285, 0.22222222222222224, 0.4, 0.3333333333333333]\n",
      "0.21842712842712847\n",
      "48\n",
      "Scores: [28.57142857142857, 61.904761904761905, 47.61904761904761, 52.38095238095239, 42.857142857142854, 52.38095238095239, 38.095238095238095, 52.38095238095239, 42.857142857142854, 38.095238095238095]\n",
      "Mean Accuracy: 45.714%\n",
      "[0.5882352941176471, 0.6, 0.5, 0.6153846153846153, 0.25, 0.2222222222222222, 0.39999999999999997, 0.5454545454545454, 0.5882352941176471, 0.3636363636363636]\n",
      "0.467316833493304\n",
      "49\n",
      "Scores: [68.18181818181817, 40.909090909090914, 72.72727272727273, 77.27272727272727, 45.45454545454545, 68.18181818181817, 63.63636363636363, 63.63636363636363, 50.0, 63.63636363636363]\n",
      "Mean Accuracy: 61.364%\n",
      "[0.5, 0.4, 0, 0, 0.25, 0.28571428571428575, 0.5714285714285715, 0.3333333333333333, 0.4444444444444445, 0.28571428571428575]\n",
      "0.3070634920634921\n",
      "50\n",
      "Scores: [33.33333333333333, 66.66666666666666, 66.66666666666666, 66.66666666666666, 66.66666666666666, 66.66666666666666, 66.66666666666666, 100.0, 66.66666666666666, 66.66666666666666]\n",
      "Mean Accuracy: 66.667%\n",
      "[0.6666666666666666, 0.8, 0, 0.6666666666666666, 0, 0, 0.6666666666666666, 0.8, 1.0, 0.5]\n",
      "0.51\n",
      "51\n",
      "Scores: [100.0, 0.0, 0.0, 0.0, 100.0, 100.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Mean Accuracy: 30.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "52\n",
      "Scores: [79.54545454545455, 70.45454545454545, 84.0909090909091, 72.72727272727273, 75.0, 77.27272727272727, 77.27272727272727, 79.54545454545455, 88.63636363636364, 70.45454545454545]\n",
      "Mean Accuracy: 77.500%\n",
      "[0.36363636363636365, 0, 0.6666666666666666, 0.4, 0.28571428571428575, 0.36363636363636365, 0.4, 0, 0, 0]\n",
      "0.24796536796536794\n",
      "53\n",
      "Scores: [82.22222222222221, 91.11111111111111, 77.77777777777779, 73.33333333333333, 82.22222222222221, 88.88888888888889, 84.44444444444444, 84.44444444444444, 77.77777777777779, 88.88888888888889]\n",
      "Mean Accuracy: 83.111%\n",
      "[0, 0.25, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.025\n",
      "54\n",
      "Scores: [60.3448275862069, 53.44827586206896, 62.06896551724138, 67.24137931034483, 55.172413793103445, 62.06896551724138, 65.51724137931035, 51.724137931034484, 63.793103448275865, 50.0]\n",
      "Mean Accuracy: 59.138%\n",
      "[0.65, 0.6190476190476191, 0.6, 0.6285714285714286, 0.6190476190476191, 0.6818181818181818, 0.6111111111111112, 0.6956521739130435, 0.6842105263157895, 0.4864864864864864]\n",
      "0.6275945146311278\n",
      "55\n",
      "Scores: [75.0, 62.5, 50.0, 75.0, 75.0, 56.25, 62.5, 75.0, 68.75, 50.0]\n",
      "Mean Accuracy: 65.000%\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "0.0\n",
      "56\n",
      "Scores: [100.0, 50.0, 100.0, 100.0, 50.0, 100.0, 0.0, 50.0, 100.0, 50.0]\n",
      "Mean Accuracy: 70.000%\n",
      "[0, 1.0, 0, 1.0, 1.0, 0, 1.0, 0, 0, 0]\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# CART algorithm,chaid ,id3 and cd4.5\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    file = open(filename, \"rt\")\n",
    "    lines = reader(file)\n",
    "    dataset = list(lines)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "def f_score_metric(actual,predicted):\n",
    "    c11=0\n",
    "    c10=0\n",
    "    c01=0\n",
    "    c00=0\n",
    "    for i in range(len(actual)):\n",
    "        if(actual[i]==1):\n",
    "            if(predicted[i]==1):\n",
    "                c11=c11+1\n",
    "            else:\n",
    "                c10=c10+1\n",
    "        else:\n",
    "            if(predicted[i]==1):\n",
    "                c01=c01+1\n",
    "            else:\n",
    "                c00=c00+1\n",
    "    if(c11+c01==0):\n",
    "        prec=0\n",
    "    else:\n",
    "        prec=c11/(c11+c01)\n",
    "    if(c11+c10==0):\n",
    "        rec=0\n",
    "    else:\n",
    "        rec=c11/(c11+c10)\n",
    "    if(prec+rec==0):\n",
    "        fsc=0\n",
    "    else:\n",
    "        fsc=2*prec*rec/(prec+rec)\n",
    "    return fsc\n",
    "\n",
    "def square(val):\n",
    "    return val*val;\n",
    "import math;\n",
    "def nos(c,in1):\n",
    "    in2=np.where(c[in1[0]]==0)\n",
    "    in3=np.where(c[in1[0]]>0)\n",
    "    return len(in2[0]),len(in3[0])\n",
    "\n",
    "def giniscal(f,c):\n",
    "    mf=np.median(f)\n",
    "    in1=np.where(f<=mf)\n",
    "    in2=np.where(f>mf)\n",
    "    n00,n01=nos(c,in1)\n",
    "    n10,n11=nos(c,in2)\n",
    "    if (n00==0 or n01==0):\n",
    "        p00=0.5\n",
    "        p01=0.5\n",
    "    else:\n",
    "        p00=n00/(n00+n01)\n",
    "        p01=n01/(n00+n01)\n",
    "    if(n10==0 or n11==0):\n",
    "        p10=0.5\n",
    "        p11=0.5\n",
    "    else:\n",
    "        p10=n10/(n10+n11)\n",
    "        p11=n11/(n10+n11)\n",
    "    gl=1-p00*p00-p01*p01;\n",
    "    gr=1-p10*p10-p11*p11;\n",
    "    fgs=len(in1[0])/(len(in1[0])+len(in2[0]))*gl+len(in2[0])/(len(in1[0])+len(in2[0]))*gr\n",
    "    return fgs\n",
    "def infoGain(f,c):\n",
    "    mf=np.median(f)\n",
    "    in1=np.where(f<=mf)\n",
    "    in2=np.where(f>mf)\n",
    "    n00,n01=nos(c,in1)\n",
    "    n10,n11=nos(c,in2)\n",
    "    en0=1\n",
    "    en1=1\n",
    "    if(n00==0 or n01==0):\n",
    "        en0=0\n",
    "    else:\n",
    "        p00=n00/(n01+n00);\n",
    "        p01=n01/(n01+n00);\n",
    "    if(n10==0 or n11==0):\n",
    "        en1=0\n",
    "    else:\n",
    "        p10=n10/(n10+n11)\n",
    "        p11=n11/(n10+n11)\n",
    "    if(en0!=0):\n",
    "        en0=-1*((p00*(math.log(p00,2)))+(p01*(math.log(p01,2))))\n",
    "    if(en1!=0):\n",
    "        en1=-1*((p10*(math.log(p10,2)))+(p11*(math.log(p11,2))))\n",
    "    val0=n00+n10\n",
    "    val1=n01+n11\n",
    "    total=val0+val1;\n",
    "    part0=n00+n01;\n",
    "    part1=n10+n11;\n",
    "    pr0=val0/(val0+val1)\n",
    "    pr1=val1/(val0+val1)\n",
    "    enP=-1*((pr0*(math.log(pr0,2)))+(pr1*(math.log(pr1,2))))\n",
    "    entr=enP-(part0*en0/total)-(part1*en1/total)\n",
    "    return entr;\n",
    "def gainRatio(f,c):\n",
    "    mf=np.median(f)\n",
    "    in1=np.where(f<=mf)\n",
    "    in2=np.where(f>mf)\n",
    "    n00,n01=nos(c,in1)\n",
    "    n10,n11=nos(c,in2)\n",
    "    gain=infoGain(f,c)\n",
    "    part0=n00+n01\n",
    "    part1=n10+n11\n",
    "    total=part0+part1\n",
    "    spart0=part0/total;\n",
    "    spart1=part1/total;\n",
    "    if(spart0==0):\n",
    "        contr0=0\n",
    "    else:\n",
    "        contr0=math.log(spart0,2)*spart0\n",
    "    if(spart1==0):\n",
    "        contr1=0\n",
    "    else:\n",
    "        contr1=(math.log(spart1,2)*spart1)\n",
    "        \n",
    "    splitInfo=-1*(contr0+contr1);\n",
    "    if(splitInfo==0):\n",
    "        fans=1\n",
    "    else:\n",
    "        fans=gain/splitInfo\n",
    "    return fans\n",
    "    \n",
    "def misclassificationError(f,c):\n",
    "    mf=np.median(f)\n",
    "    in1=np.where(f<=mf)\n",
    "    in2=np.where(f>mf)\n",
    "    n00,n01=nos(c,in1)\n",
    "    n10,n11=nos(c,in2)\n",
    "    val0=n00+n10;\n",
    "    val1=n01+n11;\n",
    "    pr0=val0/(val0+val1);\n",
    "    pr1=val1/(val0+val1);\n",
    "    fans=1-max(pr0,pr1);\n",
    "    return fans;\n",
    "def chiValueFun(f,c):\n",
    "    mf=np.median(f)\n",
    "    in1=np.where(f<=mf)\n",
    "    in2=np.where(f>mf)\n",
    "    n00,n01=nos(c,in1)\n",
    "    n10,n11=nos(c,in2)\n",
    "    c1y=n11\n",
    "    c1n=n10\n",
    "    c0y=n01\n",
    "    c0n=n00\n",
    "    valy=c1y+c0y;\n",
    "    valn=c1n+c0n;\n",
    "    val1=c1y+c1n;\n",
    "    val0=c0y+c0n;\n",
    "    summ=valy+valn+val1+val0;\n",
    "    \n",
    "    auxval1y=valy*val1/summ;\n",
    "    auxval0y=valy*val0/summ;\n",
    "    auxval1n=valn*val1/summ;\n",
    "    auxval0n=valn*val0/summ;\n",
    "    if(auxval1y==0):\n",
    "        temp1y=0;\n",
    "    else:\n",
    "        temp1y=square(auxval1y-c1y)/auxval1y;\n",
    "    if(auxval0y==0):\n",
    "        temp0y=0;\n",
    "    else:\n",
    "        temp0y=square(auxval0y-c0y)/auxval0y;\n",
    "    if(auxval1n==0):\n",
    "        temp1n=0;\n",
    "    else:\n",
    "        temp1n=square(auxval1n-c1n)/auxval1n;\n",
    "    if(auxval0n==0):\n",
    "        temp0n=0;\n",
    "    else:\n",
    "        temp0n=square(auxval0n-c0n)/auxval0n;   \n",
    "    \n",
    "    \n",
    "    \n",
    "    return temp1y+temp0y+temp1y+temp0n;\n",
    "    \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    fmsc=list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        \n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "def evaluate_fmsc(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    fmsc=list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        fmeasure=f_score_metric(actual,predicted)\n",
    "        fmsc.append(fmeasure)\n",
    "    return fmsc\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "# avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "# weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "        # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Classification and Regression Tree Algorithm\n",
    "def decision_tree(train, test, max_depth, min_size):\n",
    "    tree = build_tree(train, max_depth, min_size)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)\n",
    "def mean(arr):\n",
    "    sum=0;\n",
    "    for i in range(0,len(arr)):\n",
    "        sum=sum+arr[i]\n",
    "    sum=sum/len(arr)\n",
    "    return sum;\n",
    "\n",
    "# Test CART on Bank Note dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "for t in range(1,57):\n",
    "    filename = 'C:\\\\Users\\\\Rohan\\\\notebook\\\\dm\\\\'+str(t)+'.csv'\n",
    "    dataset = load_csv(filename)\n",
    "    fans=np.zeros((56,2))\n",
    "# convert string attributes to integers\n",
    "    for i in range(len(dataset[0])):\n",
    "        str_column_to_float(dataset, i)\n",
    "        \n",
    "    n_folds = 10\n",
    "    max_depth = 10\n",
    "    min_size = 15\n",
    "    scores = evaluate_algorithm(dataset, decision_tree, n_folds, max_depth, min_size)\n",
    "    fmeasure=evaluate_fmsc(dataset, decision_tree, n_folds, max_depth, min_size)\n",
    "    print(t)\n",
    "    print('Scores: %s' % scores)\n",
    "    print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "    print(fmeasure)\n",
    "    print(mean(fmeasure))\n",
    "    fans[t-1][0]=mean(scores)\n",
    "    fans[t-1][1]=mean(fmeasure)\n",
    "fname='C:\\\\Users\\\\Rohan\\\\notebook\\\\ass2csv\\\\dmexp\\\\'+'fans.csv'  \n",
    "np.savetxt(fname,fans, delimiter=',', fmt='%f')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "elegant-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='C:\\\\Users\\\\Rohan\\\\notebook\\\\ass2csv\\\\dmexp\\\\'+'fans.csv'  \n",
    "np.savetxt(fname,fans, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-involvement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
